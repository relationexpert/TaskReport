# Response to Reviewer 6f5c

We really appreciate all your valuable comments and will provide detailed explanations in terms of your questions and concerns below:

$\textbf{Q1:}$ The proposed model's innovation and novelty.

$\textbf{A1:}$ Thank you for your comments. While we incorporate existing techniques, our innovation lies in their novel combination and application to e-commerce challenges:

1. We are the first to apply hypergraph contrastive learning to capture complex group-wise relationships in e-commerce data.
2. Our dual-level contrastive strategy (user-level and group-level) is tailored for e-commerce scenarios.
3. The integration of RelationEmbed with TaskReport creates a comprehensive framework for both powerful representations and interpretable insights.

$\textbf{Q2:}$ Unclear augmentation strategy.

$\textbf{A2:}$ We apologize for the confusion. We use both hyperedge perturbation and attribute feature masking as augmentation strategies. Hyperedge removal is part of the hyperedge perturbation process. As suggested by existing work HyperGCL [1] in Section 3.2 that adding a hyperedge is confronted with the combinatorial challenge, we follow the setting of HyperGCL to  mainly randomly remove some hyperedges following an i.i.d. Bernoulli distribution. We'll revise this section to make it clearer in our revisions.

$\textbf{Q3:}$ Lack of clarity in formula explanation.

$\textbf{A3:}$ Thank you for your suggestion. But we believe all of the symbols in Eq. 2 have the corresponding explanations. Specifically, $Z_{e,:}^{(t)}$ and $U_{v,:}^{(t)}$ are the embeddings of hyperedge $e$ and node $v$ at time $t$, which are explained in **lines 437 - 438**.

Besides, $f_{V→E}$ and $f_{E→V}$ are learnable functions that aggregate information from nodes to hyperedges and vice versa, which are explained in **lines 438 - 439**. 
 
What’s more, $V_{e, U^(t)}$ represents the set of node embeddings connected to hyperedge e at time t, and $E_{v, Z^(t+1)}$ represents the set of hyperedge embeddings connected to node v at time t+1. While these two symbols are not directly mentioned  in this paragraph, the related symbols of $V$  and $E$ are explained in **Definition 3.1**. For clarity, we will add it to the paragraph after Eq. 2 in our revisions.

$\textbf{Q4:}$ Insufficient interpretability of the TaskReport module.

$\textbf{A4:}$ Thank you for your advice. Due to the space limits, we did not attach our detailed prompting and our figure. So it may cause some confusions in interpretability. 

Next, we will provide more details about our TaskReport. In our TaskReport, we designed a zero-shot prompting to LLM models (i.e., Claude Sonnet) to generate the report related to downstream tasks. In order to evaluate the quality of the generated report, we employ different LLM models (i.e., Claude Sonnet 3.5 and GPT-4o) to assess the factuality and clarity. 

Below this link https://anonymous.4open.science/r/TaskReport-4AD5/TaskReport.md provides the detailed prompting of TaskReport and the detailed prompting of LLM-as-a-Judge for assessing the quality of the reports. To improve the clarity, we also provide a figure to illustrate the differences between reports generated by human investigators and LLM models. We hope this link can facilitate your understanding of our TaskReport. 

While existing methods can generate reports, our TaskReport module is specifically designed to interpret complex e-commerce relationships learned by RelationEmbed. It provides insights into group-wise behaviors and multi-modal features, which are not typically addressed by general-purpose interpretation methods. We'll emphasize these unique aspects more clearly in the paper.

$\textbf{Q5:}$ Incomplete experimental design: The experimental setup does not specify how the training, validation, and test sets are divided, nor does it mention the source of the dataset used in the experiments, which might lead readers to suspect that a specific dataset was used, possibly causing experimental bias.

$\textbf{A5:}$ Thanks for your comments. While we need to say, these experimental setups including data splitting (line 617- 619 for Dataset 1 on M1 market, and line 625- 626 for Dataset 2 on  M2 market) and data details are already introduced in Section 5.1.1. Specifically, for data splitting strategy, we split the labeled data into three sets, i.e., training dataset, validation dataset, and testing dataset, according to their action time. Let us take abuser detection data as an example. We collect the time period data from Sept 1st, 2024 to Sept 30th, 2024. If the action date of users and groups before Sept 15th, 2024, then they are considered as labeled abusive data for model training. If the action date of users and groups  is between Sept 15th and Sept 30th, they are considered as validation data. If the action date of users and groups is after Sept 30th, these users and groups are considered as testing data. Due to the privacy issues of customer data, we are unable to disclose more details about that. We hope this explanation can alleviate your concerns.

$\textbf{Q6:}$  Lack of deep analysis in experimental results in Table 1 and Table 2.

$\textbf{A6:}$ Thanks for your suggestions. We will have a deep analysis on the experimental results of two downstream tasks in Tables 1 and 2.  

First of all, RelationEmbed consistently outperforms all baseline methods across different tasks and markets. This consistency demonstrates the model's robustness and generalizability. The reason is that the hypergraph structure and dual-level contrastive learning approach allow RelationEmbed to capture complex relationships that are common across different e-commerce scenarios, regardless of the specific task or market.

Besides, In Table 1, RelationEmbed shows stronger performance in merchant detection compared to customer and group detection. This could indicate that merchant behavior patterns are more distinctive or that the model is particularly effective at capturing merchant-related features. Merchants likely have more consistent and identifiable patterns of behavior across multiple transactions and customer interactions, making their representations easier to learn and distinguish.

Moreover, Table 2 shows that Weight-L2 consistently outperforms Hadamard for link prediction across all models.
The reason can be Weight-L2 operation might be more effective at capturing the relationship between products and customers in the embedding space because it allows for a more nuanced comparison of feature importance. The L2 distance can capture both the magnitude and direction of differences in the embedding space, which may be more relevant for e-commerce relationships than the element-wise multiplication of Hadamard.

I hope these deep analysis can facilitate your understanding of our experiments.


$\textbf{Q7:}$ Unclear result calculation and interpretation: In the experimental results in Table 3, the authors do not explain how the authenticity and clarity metrics were calculated, nor do they clarify how the values in Table 3 were obtained or what they represent.

$\textbf{A7:}$ As discussed in Lines 896 - 901 in Section 5.3,  factuality aims to assess whether these statements in the report are correct or not based on the input data (i.e., relation triplets and predicted labels of associated users). clarity aims to evaluate whether the report is clear and easy to understand.  Specifically, factuality and clarity were evaluated on a 1-3 scale by two LLM models (Claude 3 Sonnet 3.5 and GPT-4o) acting as judges. As discussed in Lines 902 - 905, for each task, 500 reports were generated and evaluated. The values in Table 3 represent the mean scores across these 500 reports, with standard deviations provided. A score of 1 indicates incorrect/unclear, 2 indicates partially correct/clear, and 3 indicates correct/clear.

$\textbf{Q8:}$ Necessity of using LLMs for interpretability reports.

$\textbf{A8:}$ LLMs offer unique advantages for our framework, including deep contextual understanding, flexibility across various scenarios, and the ability to produce human-readable explanations accessible to non-technical stakeholders.

We sincerely hope our responses have addressed your concerns. We appreciate your recognition of our novel model design and would be grateful for your support. Please let us know if you have any further questions or comments.
